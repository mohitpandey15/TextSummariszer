{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT SUMMARIZATION**\n",
        "\n",
        "> **Extractive summarization**\n"
      ],
      "metadata": {
        "id": "SPRpEebrHXU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hUEepsYt5O7j"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import re\n",
        "from google.colab import files  # Import the 'files' module for file downloads"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "id": "TQgG7FyiGNZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0665b55a-79ef-4b17-d589-fdf04b10a4d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_article(file_content):\n",
        "    sentences = nltk.sent_tokenize(file_content)\n",
        "    return sentences\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    return re.sub(r'[^a-zA-Z]', ' ', sentence).lower()"
      ],
      "metadata": {
        "id": "67G6O2nFGSKd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_similarity(sent1, sent2):\n",
        "    sent1 = nltk.word_tokenize(sent1)\n",
        "    sent2 = nltk.word_tokenize(sent2)\n",
        "    all_words = list(set(sent1 + sent2))\n",
        "    vector1 = [sent1.count(word) for word in all_words]\n",
        "    vector2 = [sent2.count(word) for word in all_words]\n",
        "    return 1 - cosine_distance(vector1, vector2)"
      ],
      "metadata": {
        "id": "QoC-wwL2GZv_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_similarity_matrix(sentences):\n",
        "    num_sentences = len(sentences)\n",
        "    similarity_matrix = np.zeros((num_sentences, num_sentences))\n",
        "\n",
        "    for i in range(num_sentences):\n",
        "        for j in range(num_sentences):\n",
        "            if i != j:\n",
        "                similarity_matrix[i][j] = sentence_similarity(sentences[i], sentences[j])\n",
        "\n",
        "    return similarity_matrix"
      ],
      "metadata": {
        "id": "mqjfSCC3Gcnz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(file_content):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    sentences = read_article(file_content)\n",
        "\n",
        "    # Extractive Summarization\n",
        "    sentence_similarity_matrix = build_similarity_matrix(sentences)\n",
        "    sentence_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
        "    scores = nx.pagerank(sentence_graph)\n",
        "    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n",
        "    top_sentences = [sentence for score, sentence in ranked_sentences[:5]]  # Summarize into 5 sentences\n",
        "\n",
        "    summarized_text = \" \".join(top_sentences)  # Summarize into a paragraph\n",
        "    return summarized_text"
      ],
      "metadata": {
        "id": "7RB-QbtYGgFZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Interaction\n",
        "print(\"Text Summarization Tool\")\n",
        "input_choice = input(\"Choose input method (text/file): \").lower()\n",
        "\n",
        "# Initialize file_content as an empty string\n",
        "file_content = \"\"\n",
        "\n",
        "if input_choice == \"text\":\n",
        "    file_content = input(\"Enter the text for summarization: \")\n",
        "elif input_choice == \"file\":\n",
        "    # Upload your text file to Google Colab\n",
        "    uploaded_file = files.upload()\n",
        "\n",
        "    # Read the uploaded file\n",
        "    file_content = list(uploaded_file.values())[0].decode(\"utf-8\")\n",
        "else:\n",
        "    print(\"Invalid input method. Please choose 'text' or 'file'.\")\n",
        "\n",
        "try:\n",
        "    # Generate the summary\n",
        "    summary = generate_summary(file_content)\n",
        "\n",
        "    # Print the summary\n",
        "    print(\"Summarized Text:\\n\", summary)\n",
        "\n",
        "    # Save the summary to a temporary file\n",
        "    with open(\"summary.txt\", \"w\") as output_file:\n",
        "        output_file.write(summary)\n",
        "\n",
        "    # Provide a link for the user to download the summarized text\n",
        "    files.download(\"summary.txt\")  # Download the summarized text\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "cGSTG370GlCP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "0f6a55d2-3fd5-4ca4-9c52-38c5d09f0ca9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Summarization Tool\n",
            "Choose input method (text/file): text\n",
            "Enter the text for summarization: Batman's origin story features him swearing vengeance against criminals after witnessing the murder of his parents Thomas and Martha as a child, a vendetta tempered with the ideal of justice. He trains himself physically and intellectually, crafts a bat-inspired persona, and monitors the Gotham streets at night.\n",
            "Summarized Text:\n",
            " He trains himself physically and intellectually, crafts a bat-inspired persona, and monitors the Gotham streets at night. Batman's origin story features him swearing vengeance against criminals after witnessing the murder of his parents Thomas and Martha as a child, a vendetta tempered with the ideal of justice.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eb796b3c-2e55-4597-9bb7-b02ebe375737\", \"summary.txt\", 313)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HbzL4CuGpYW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}